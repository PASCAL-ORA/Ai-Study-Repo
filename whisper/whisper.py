#!/usr/bin/env python
# coding: utf-8

# In[2]:


# ------------------------------
# ğŸ”§ 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸
# ------------------------------
get_ipython().system('pip install librosa jiwer transformers tqdm pandas --quiet')
get_ipython().system('pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu --quiet')

import os
import json
import re
import random
import torch
import librosa
import pandas as pd
from tqdm import tqdm
from jiwer import cer
from transformers import WhisperProcessor, WhisperForConditionalGeneration


# In[3]:

print("Hello")

# ------------------------------
# ğŸ“ 2. ê²½ë¡œ ì„¤ì •
# ------------------------------
AUDIO_DIR = r"C:\Users\cy\Downloads\139-1.ì¤‘Â·ë…¸ë…„ì¸µ í•œêµ­ì–´ ë°©ì–¸ ë°ì´í„° (ê°•ì›ë„, ê²½ìƒë„)\01-1.ì •ì‹ê°œë°©ë°ì´í„°\Training\01.ì›ì²œë°ì´í„°"
LABEL_DIR = r"C:\Users\cy\Downloads\139-1.ì¤‘Â·ë…¸ë…„ì¸µ í•œêµ­ì–´ ë°©ì–¸ ë°ì´í„° (ê°•ì›ë„, ê²½ìƒë„)\01-1.ì •ì‹ê°œë°©ë°ì´í„°\Training\02.ë¼ë²¨ë§ë°ì´í„°\TL_02. ê²½ìƒë„_02. 1ì¸ë°œí™” ì§ˆë¬¸ì—ë‹µí•˜ê¸°"
OUTPUT_CSV = "cer_results.csv"


# In[4]:


# ------------------------------
# ğŸ¤– 3. Whisper ëª¨ë¸ ë¡œë”©
# ------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
model_name = "openai/whisper-small"
processor = WhisperProcessor.from_pretrained(model_name)
model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)


# In[5]:


# ------------------------------
# ğŸ§¼ 4. í•œê¸€ í…ìŠ¤íŠ¸ ì •ê·œí™” í•¨ìˆ˜
# ------------------------------
def normalize_korean(text):
    text = re.sub(r"[^ã„±-ã…ê°€-í£0-9a-zA-Z\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text.lower()


# In[6]:


# ------------------------------
# ğŸ”Š 5. ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
# ------------------------------
def load_audio(file_path, target_sr=16000):
    audio, _ = librosa.load(file_path, sr=target_sr)
    return audio


# In[7]:


# ------------------------------
# ğŸ—£ï¸ 6. ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ í•¨ìˆ˜
# ------------------------------
def transcribe(audio):
    inputs = processor(audio, sampling_rate=16000, return_tensors="pt", return_attention_mask=True)
    forced_decoder_ids = processor.get_decoder_prompt_ids(language="ko", task="transcribe")
    outputs = model.generate(
        inputs.input_features.to(device),
        attention_mask=inputs.attention_mask.to(device),
        forced_decoder_ids=forced_decoder_ids
    )
    return processor.batch_decode(outputs, skip_special_tokens=True)[0]


# In[8]:


# ------------------------------
# ğŸš€ 7. í‰ê°€ ìˆ˜í–‰ (4000ê°œ ë¬´ì‘ìœ„)
# ------------------------------
results = []
total_cer = 0
count = 0

print("ğŸ’¬ CER í‰ê°€ ì‹œì‘...")


# In[9]:


# ë¬´ì‘ìœ„ ìƒ˜í”Œë§
all_audio_files = [f for f in os.listdir(AUDIO_DIR) if f.endswith(".wav")]
random.seed(42)  # ë™ì¼í•œ ê²°ê³¼ ì¬í˜„ìš©
sample_audio_files = random.sample(all_audio_files, min(4000, len(all_audio_files)))

for audio_file in tqdm(sample_audio_files, desc="Evaluating", unit="file"):
    file_id = os.path.splitext(audio_file)[0]
    audio_path = os.path.join(AUDIO_DIR, audio_file)
    json_path = os.path.join(LABEL_DIR, file_id + ".json")

    if not os.path.exists(json_path):
        print(f"[WARN] ë¼ë²¨ë§ ëˆ„ë½: {file_id}")
        continue

    try:
        # ì •ë‹µ ë¬¸ì¥ ë¶ˆëŸ¬ì˜¤ê¸°
        with open(json_path, "r", encoding="utf-8") as jf:
            data = json.load(jf)
            reference = data.get("transcription", {}).get("standard", "").strip()

        if not reference:
            print(f"[WARN] ì •ë‹µ ëˆ„ë½: {file_id}")
            continue

        # ìŒì„± â†’ í…ìŠ¤íŠ¸
        audio = load_audio(audio_path)
        hypothesis = transcribe(audio)

        # CER ê³„ì‚°
        ref_norm = normalize_korean(reference)
        hyp_norm = normalize_korean(hypothesis)
        file_cer = cer(ref_norm, hyp_norm)

        # ê²°ê³¼ ì €ì¥
        total_cer += file_cer
        count += 1
        results.append({
            "file_id": file_id,
            "audio_file": audio_file,
            "reference": ref_norm,
            "hypothesis": hyp_norm,
            "cer": round(file_cer, 3)
        })

    except Exception as e:
        print(f"[ERROR] {file_id}: {e}")


# In[10]:


# ------------------------------
# ğŸ’¾ 8. ê²°ê³¼ ì €ì¥ ë° í‰ê·  CER ì¶œë ¥
# ------------------------------
df = pd.DataFrame(results)
df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")

if count > 0:
    print(f"\nâœ… í‰ê·  CER: {total_cer / count:.3f} ({count}ê°œ íŒŒì¼ ê¸°ì¤€)")
else:
    print("âŒ í‰ê°€í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


# In[ ]:




